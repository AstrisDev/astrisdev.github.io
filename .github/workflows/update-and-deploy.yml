name: Update Data and Deploy

on:
    schedule:
        - cron: "0 */6 * * *"
    workflow_dispatch:
        inputs:
            force_scrape:
                description: "Force scrape rusmarka.ru"
                required: false
                default: false
                type: boolean

jobs:
    update-and-deploy:
        runs-on: ubuntu-latest
        permissions:
            contents: write
            pages: write
            id-token: write

        environment:
            name: github-pages
            url: ${{ steps.deployment.outputs.page_url }}

        steps:
            - name: Checkout main repo
              uses: actions/checkout@v4
              with:
                  token: ${{ secrets.GITHUB_TOKEN }}

            - name: Setup Node.js
              uses: actions/setup-node@v4
              with:
                  node-version: "18"
                  cache: "npm"
                  cache-dependency-path: frontend/package-lock.json

            - name: Setup Go
              uses: actions/setup-go@v4
              with:
                  go-version: "1.21"

            - name: Build tools
              run: |
                  cd tools
                  CGO_ENABLED=0 go build -o sfwatch -buildvcs=false ./cmd/sfwatch
                  CGO_ENABLED=0 go build -o sfscrape -buildvcs=false ./cmd/sfscrape

            - name: Build frontend
              run: |
                  cd frontend
                  npm ci
                  npm run build
              env:
                  VITE_SF_STAMPS_DATA_URL: "./data/stamps.json"
                  VITE_SF_SHOPS_DATA_URL: "./data/shops.json"

            - name: Initialize site directory
              run: |
                  mkdir -p ./site-output
                  echo "Starting sfwatch initialization..."

                  # Запускаем sfwatch в фоне
                  ./tools/sfwatch -r ./site-output -f ./frontend/dist --update-period=30s --disable-rusmarka &
                  SFWATCH_PID=$!

                  echo "Waiting for data repository to be cloned..."

                  # Ждем пока появится stamps.json (максимум 10 минут)
                  for i in {1..120}; do
                    if [ -f "./site-output/repo/stamps.json" ]; then
                      echo "Data repository cloned successfully!"
                      break
                    fi
                    echo "Waiting for repository... (${i}/120)"
                    sleep 5
                  done

                  # Останавливаем sfwatch
                  echo "Stopping sfwatch..."
                  kill $SFWATCH_PID 2>/dev/null || true
                  wait $SFWATCH_PID 2>/dev/null || true

                  if [ ! -f "./site-output/repo/stamps.json" ]; then
                    echo "ERROR: stamps.json not found, initialization failed"
                    exit 1
                  fi

                  echo "Basic initialization completed"

            - name: Run scraper if needed
              if: ${{ github.event.inputs.force_scrape == 'true' || github.event_name == 'schedule' }}
              run: |
                  if [ -f "./site-output/repo/stamps.json" ]; then
                    echo "Running scraper to update data..."

                    timeout 1200 ./tools/sfscrape -n -c ./site-output/repo || {
                      echo "Scraper timeout or completed"
                    }

                    if git -C ./site-output/repo status --porcelain | grep -q .; then
                      echo "DATA_UPDATED=true" >> $GITHUB_ENV

                      cd ./site-output/repo
                      git config user.name "GitHub Actions"
                      git config user.email "actions@github.com"
                      git add .
                      git commit -m "Auto-update stamps data $(date '+%Y-%m-%d %H:%M:%S')" || true

                      echo "Data changes committed locally"
                    else
                      echo "DATA_UPDATED=false" >> $GITHUB_ENV
                      echo "No data changes detected"
                    fi
                  fi

            - name: Generate final site
              run: |
                  echo "Generating final site..."

                  # Запускаем sfwatch в фоне для генерации финального сайта
                  ./tools/sfwatch -r ./site-output -f ./frontend/dist --update-period=30s --disable-rusmarka &
                  SFWATCH_PID=$!

                  echo "Waiting for pages to be generated..."

                  # Ждем пока сгенерируются страницы (максимум 5 минут)
                  for i in {1..60}; do
                    if [ -d "./site-output/pages" ] && [ "$(ls -A ./site-output/pages 2>/dev/null)" ]; then
                      echo "Site generation completed successfully!"
                      break
                    fi
                    echo "Waiting for site generation... (${i}/60)"
                    sleep 5
                  done

                  # Останавливаем sfwatch
                  echo "Stopping sfwatch..."
                  kill $SFWATCH_PID 2>/dev/null || true
                  wait $SFWATCH_PID 2>/dev/null || true

                  if [ ! -d "./site-output/pages" ] || [ ! "$(ls -A ./site-output/pages 2>/dev/null)" ]; then
                    echo "ERROR: pages directory not found or empty"
                    ls -la ./site-output/ 2>/dev/null || echo "site-output directory doesn't exist"
                    exit 1
                  fi

                  echo "Site generation completed"
                  ls -la ./site-output/pages/

            - name: Setup Pages
              uses: actions/configure-pages@v4

            - name: Upload artifact
              uses: actions/upload-pages-artifact@v3
              with:
                  path: "./site-output/pages"

            - name: Deploy to GitHub Pages
              id: deployment
              uses: actions/deploy-pages@v4
